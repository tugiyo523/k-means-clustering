{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0efad897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cek\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    import numpy as np\n",
    "    import xarray as xr\n",
    "\n",
    "    from xlearn22.cluster import KMeans as KMeans22\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    from kneed import KneeLocator\n",
    "    from gap_statistic import OptimalK\n",
    "    from sklearn.datasets import make_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac3938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    n_clusters=15\n",
    "    annual_cycle=False\n",
    "    with_pca=False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09fd9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 2\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 3\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 4\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 5\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 6\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 7\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 8\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 9\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 10\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 11\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 12\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 13\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "k= 14\n",
      "-------- clustering... fit3 .... ------------------\n",
      "fit dari sklearn cluster KMeans\n",
      "Optimum cluster SSE= 8\n",
      "Optimum cluster SHS= 12\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "fit dari sklearn cluster KMeans\n",
      "Optimal number of clusters 2: 12\n",
      "2\n",
      "fit dari sklearn cluster KMeans\n",
      "3\n",
      "fit dari sklearn cluster KMeans\n",
      "4\n",
      "fit dari sklearn cluster KMeans\n",
      "5\n",
      "fit dari sklearn cluster KMeans\n",
      "6\n",
      "fit dari sklearn cluster KMeans\n",
      "7\n",
      "fit dari sklearn cluster KMeans\n",
      "8\n",
      "fit dari sklearn cluster KMeans\n",
      "9\n",
      "fit dari sklearn cluster KMeans\n",
      "10\n",
      "fit dari sklearn cluster KMeans\n",
      "11\n",
      "fit dari sklearn cluster KMeans\n",
      "12\n",
      "fit dari sklearn cluster KMeans\n",
      "13\n",
      "fit dari sklearn cluster KMeans\n",
      "14\n",
      "fit dari sklearn cluster KMeans\n",
      "15\n",
      "fit dari sklearn cluster KMeans\n",
      "Optimal number of clusters 1: 12\n",
      "Sk 1    0.004122680362918948\n",
      "Sk 2    0.004220185267303469\n",
      "Sk 3    0.0040858503023555506\n",
      "Sk 4    0.004975162115008315\n",
      "Sk 5    0.0046676106063883935\n",
      "Sk 6    0.003988320850171247\n",
      "Sk 7    0.0040947299580809575\n",
      "Sk 8    0.0042399016522750264\n",
      "Sk 9    0.005272299642013322\n",
      "Sk 10    0.0037167399657788546\n",
      "Sk 11    0.004373767633888485\n",
      "Sk 12    0.004667480759775998\n",
      "Sk 13    0.005179189562657936\n",
      "Sk 14    0.004400278716099981\n",
      "Optimal number of clusters: 1.0\n",
      "metrik= [8, 12, 12, 12, 1.0]\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "        #variasi dan set jumlah kluster pada data sintetik \n",
    "        for c in [12]:\n",
    "            # Generate synthetic data n centers\n",
    "            X, y = make_blobs(n_samples=7500, n_features=12, centers=c, random_state=42)\n",
    "            \n",
    "            # mau rubah n_samples? rubah juga lats, lons dan harus n_samples= lats x lons\n",
    "           \n",
    "            lon_values = np.linspace(90, 144, 100)\n",
    "            lat_values = np.linspace(-10, 7, 75)\n",
    "\n",
    "            # Create coordinate arrays\n",
    "            lon, lat = np.meshgrid(lon_values, lat_values)\n",
    "\n",
    "            # Reshape data to fit the lon/lat grid\n",
    "            X_reshaped = X.reshape((len(lon_values), len(lat_values), -1))\n",
    "\n",
    "            # Create xarray DataArray\n",
    "            data_array = xr.DataArray(X_reshaped, coords=[('lon', lon_values), ('lat', lat_values), ('feature', np.arange(12))])\n",
    "\n",
    "            dm=data_array.stack(z=(\"lat\", \"lon\")) \n",
    "            \n",
    "            metrik=[]       \n",
    "            sse = []\n",
    "            silhouette_coef = []\n",
    "           \n",
    "            for k in range(1, n_clusters):\n",
    "                print('k=',k)\n",
    "                kmeans, features = KMeans22(n_clusters=k,  random_state=42).fit3(dm, annual_cycle, with_pca=False)\n",
    "                                    \n",
    "                sse.append(kmeans.inertia_) \n",
    "               \n",
    "                if k>1:\n",
    "                    label2=kmeans.cluster_centers_da.sel(cluster=0).stack(z=(\"lat\", \"lon\"))\n",
    "                    label2=label2.dropna(dim=('z'))\n",
    "                    #print('label2', label2)\n",
    "                    score = silhouette_score(features, label2)\n",
    "                else:\n",
    "                    score=0\n",
    "                silhouette_coef.append(score)\n",
    "            \n",
    "            kl = KneeLocator(\n",
    "                range(1, n_clusters), sse, curve=\"convex\", direction=\"decreasing\"\n",
    "                )\n",
    "            c=kl.elbow\n",
    "            print('Optimum cluster SSE=',c)\n",
    "            metrik.append(c)\n",
    "       \n",
    "            s=np.array(silhouette_coef)\n",
    "            c2=np.where(s==s.max())[0][0]+1\n",
    "            \n",
    "            print('Optimum cluster SHS=',c2)\n",
    "            metrik.append(c2)\n",
    "            X=dm.T\n",
    "            # Membuang np.NaN (for land only)\n",
    "            valid_features_index = ~np.isnan(X[:,0])\n",
    "            X_valid = X[valid_features_index.data,:]\n",
    "            X=X_valid\n",
    "            \n",
    "            from sklearn.cluster import KMeans\n",
    "            from sklearn.metrics import pairwise_distances_argmin_min\n",
    "            from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score\n",
    "            \n",
    "            #CHI\n",
    "            #--- calinski_harabasz_score\n",
    "            def find_optimal_clusters(X, max_clusters=n_clusters):\n",
    "                #Find the optimal number of clusters that maximizes the Calinski-Harabasz index.\n",
    "                calinski_harabasz_scores = []\n",
    "                for k in range(2, max_clusters + 1):\n",
    "                    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "                    labels = kmeans.fit_predict(X)\n",
    "                    ch_score = calinski_harabasz_score(X, labels)\n",
    "                    calinski_harabasz_scores.append(ch_score)\n",
    "\n",
    "                # Find the number of clusters with the maximum Calinski-Harabasz index\n",
    "                optimal_clusters = np.argmax(calinski_harabasz_scores) + 2  # Add 2 because we started from k=2\n",
    "                return optimal_clusters\n",
    "                \n",
    "            # Call\n",
    "            optimal_clusters = find_optimal_clusters(X)\n",
    "            print(f\"Optimal number of clusters 2: {optimal_clusters}\")\n",
    "            metrik.append(optimal_clusters)\n",
    "            \n",
    "            #DBI\n",
    "            # ini dari chatGPT hasil tidak = yg dari sklearn\n",
    "            def davies_bouldin_index(X, labels):\n",
    "                \n",
    "                #Calculate the Davies-Bouldin index for a given clustering.\n",
    "\n",
    "                k = len(np.unique(labels))\n",
    "                #print('len(np.unique(labels))=', k)\n",
    "                cluster_centers = [np.mean(X[labels == i], axis=0) for i in range(k)]\n",
    "\n",
    "                # Calculate pairwise distances between cluster centers\n",
    "                center_distances = pairwise_distances_argmin_min(cluster_centers, cluster_centers)\n",
    "\n",
    "                # Calculate cluster-wise Davies-Bouldin index\n",
    "                db_index = 0.0\n",
    "                for i in range(k):\n",
    "                    max_ratio = 0.1\n",
    "                    for j in range(k):\n",
    "                        if i != j:\n",
    "                            ratio = (np.sum(pairwise_distances_argmin_min(X[labels == i], X[labels == j])[1]) +\n",
    "                                     np.sum(pairwise_distances_argmin_min(X[labels == j], X[labels == i])[1])) \\\n",
    "                                     / center_distances[1][i]\n",
    "                            if ratio > max_ratio:\n",
    "                                max_ratio = ratio\n",
    "                    db_index += max_ratio\n",
    "\n",
    "                return db_index / k\n",
    "\n",
    "            def find_optimal_clusters(X, max_clusters=n_clusters):\n",
    "              \n",
    "                #Find the optimal number of clusters that minimizes the Davies-Bouldin index.\n",
    "                \n",
    "                davies_bouldin_scores = []\n",
    "\n",
    "                for k in range(2, max_clusters + 1):\n",
    "                    print(k)\n",
    "                    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "                    labels = kmeans.fit_predict(X)\n",
    "                    #db_score = davies_bouldin_index(X, labels)\n",
    "                    #ini dari sklearn \n",
    "                    db_score = davies_bouldin_score(X, labels)\n",
    "                    davies_bouldin_scores.append(db_score)\n",
    "\n",
    "                # Find the number of clusters with the minimum Davies-Bouldin index\n",
    "                optimal_clusters = np.argmin(davies_bouldin_scores) + 2  \n",
    "                # Add 2 because we started from k=2\n",
    "                return optimal_clusters\n",
    "\n",
    "            # Call\n",
    "            optimal_clusters = find_optimal_clusters(X)\n",
    "            print(f\"Optimal number of clusters 1: {optimal_clusters}\")\n",
    "            metrik.append(optimal_clusters)\n",
    "            \n",
    "            #GP\n",
    "\n",
    "            optimal_k = OptimalK(parallel_backend='rust')\n",
    "            #optimal_k = OptimalK(parallel_backend='joblib') #ini hasilnya aneh\n",
    "            #optimal_k = OptimalK() #ini hasilnya aneh\n",
    "            optimal_k_clusters = optimal_k(X_valid, cluster_array=np.arange(1, n_clusters), \n",
    "                                           n_refs=50)\n",
    "            \n",
    "            self=optimal_k\n",
    "            \n",
    "            '''\n",
    "            # Print the optimal number of clusters\n",
    "            print(\"Optimal number of clusters:\", optimal_k_clusters)\n",
    "\n",
    "            # Plot Gap Statistics\n",
    "            #optimal_k.plot_results()\n",
    "\n",
    "            # Gap values plot\n",
    "            \n",
    "            ax[0,i].plot(self.gap_df.n_clusters, self.gap_df.gap_value, linewidth=3)\n",
    "            ax[0,i].scatter(\n",
    "            self.gap_df[self.gap_df.n_clusters == self.n_clusters].n_clusters,\n",
    "            self.gap_df[self.gap_df.n_clusters == self.n_clusters].gap_value,\n",
    "            s=250,\n",
    "            c=\"r\",\n",
    "            )\n",
    "            \n",
    "            \n",
    "            # Gap* plot\n",
    "            max_ix = self.gap_df[self.gap_df[\"gap*\"] == self.gap_df[\"gap*\"].max()].index[0]\n",
    "            ax[0,i+1].plot(self.gap_df.n_clusters, self.gap_df[\"gap*\"], linewidth=3)\n",
    "            ax[0,i+1].scatter(\n",
    "                self.gap_df.loc[max_ix][\"n_clusters\"],\n",
    "                self.gap_df.loc[max_ix][\"gap*\"],\n",
    "                s=250,\n",
    "                c=\"r\",\n",
    "            )\n",
    "            plt.show()\n",
    "            '''\n",
    "            max_ix = self.gap_df[self.gap_df[\"gap*\"] == self.gap_df[\"gap*\"].max()].index[0]\n",
    "            \n",
    "            print(\"Optimal number of clusters:\", self.gap_df.loc[max_ix][\"n_clusters\"])\n",
    "            \n",
    "            metrik.append(self.gap_df.loc[max_ix][\"n_clusters\"])\n",
    "            \n",
    "    print('metrik=', metrik)\n",
    "            \n",
    "            \n",
    "        \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d0fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7bb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8342546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
